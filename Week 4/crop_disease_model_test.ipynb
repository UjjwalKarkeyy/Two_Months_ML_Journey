{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0d0a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 15:52:53.712534: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-25 15:52:53.957105: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-25 15:52:56.006178: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skimage import color, transform\n",
    "from pathlib import Path\n",
    "import keras\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9556f8",
   "metadata": {},
   "source": [
    "## Loading Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "843ab892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/root123/GitHub/Two_Months_ML_Journey/Week 4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_dir = os.getcwd()\n",
    "curr_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b531e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761386882.973982    3689 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "cnn = keras.saving.load_model(f'{curr_dir}/saved_models/cnn_scratch_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6b15f",
   "metadata": {},
   "source": [
    "## Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de4727e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a function transformer to pass it to pipeline\n",
    "\n",
    "# def preprocess(img):\n",
    "#     # Convert PIL Image → NumPy array\n",
    "#     if isinstance(img, Image.Image):\n",
    "#         img = np.array(img)\n",
    "#     # grayscale (no channel dimension)\n",
    "#     if img.ndim == 2:\n",
    "#         img = color.gray2rgb(img)\n",
    "#         print('Gray to RGB')\n",
    "#     # RGBA (4 channels)\n",
    "#     elif img.shape[2] == 4:\n",
    "#         img = color.rgba2rgb(img)\n",
    "#         print('RGBA to RGB')\n",
    "\n",
    "#     # Resize to 128x128\n",
    "#     resized_img = transform.resize(img, (128, 128), anti_aliasing=True) # anti_aliasing makes img smoother when shrinked\n",
    "#     resized_img = resized_img.astype('float32')\n",
    "#     norm_resized_img = resized_img / 255.0\n",
    "#     return norm_resized_img\n",
    "\n",
    "# # converting our function to 'Function Transformer' for compatibility with Sklearn's pipeline\n",
    "# rgb_resize_transformer = FunctionTransformer(\n",
    "#     lambda imgs: np.array([preprocess(img) for img in imgs])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6769fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasPreprocessorWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_size=(128, 128)):\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # no learning from data here, but required by sklearn's API\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "            # Convert PIL images to numpy arrays if needed\n",
    "        if isinstance(X, list):\n",
    "            X = [np.array(img) if hasattr(img, 'size') else img for img in X]\n",
    "            X = np.stack(X, axis=0)  # shape: (batch, H, W, C)\n",
    "        elif isinstance(X, Image.Image):  # single image\n",
    "            X = np.expand_dims(np.array(X), axis=0)\n",
    "        # Ensure the input is a TensorFlow tensor\n",
    "        X = tf.convert_to_tensor(X)\n",
    "\n",
    "        # Normalize dtype and scale to [0,1]\n",
    "        X = tf.image.convert_image_dtype(X, tf.float32)\n",
    "\n",
    "        # Handle grayscale (1 channel) or RGBA (4 channels)\n",
    "        num_channels = tf.shape(X)[-1]\n",
    "\n",
    "        def to_rgb_if_grayscale():\n",
    "            return tf.image.grayscale_to_rgb(X)\n",
    "\n",
    "        def to_rgb_if_rgba():\n",
    "            return X[..., :3]\n",
    "\n",
    "        def identity():\n",
    "            return X\n",
    "\n",
    "        X = tf.case(\n",
    "            [\n",
    "                (tf.equal(num_channels, 1), to_rgb_if_grayscale),\n",
    "                (tf.equal(num_channels, 4), to_rgb_if_rgba)\n",
    "            ],\n",
    "            default=identity,\n",
    "            exclusive=True\n",
    "        )\n",
    "\n",
    "        # Resize to target size\n",
    "        X = tf.image.resize(X, self.target_size)\n",
    "\n",
    "        # Return a TensorFlow tensor (not NumPy)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923177a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocess', KerasPreprocessorWrapper()),\n",
    "    ('model', cnn),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4d975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_path = 'test_data'\n",
    "predict_img_path = curr_dir/Path(destination_path)\n",
    "predictions = [\n",
    "    'Pepper Bell Bacterial Spot',\n",
    "    'Pepper Bell Healthy',\n",
    "    'Potato Early Blight',\n",
    "    'Potato Healthy',\n",
    "    'Potato Late Blight',\n",
    "    'Tomato Target Spot',\n",
    "    'Tomato Mosaic Virus',\n",
    "    'Tomato Yellow Leaf Curl Virus',\n",
    "    'Tomato Bacterial Spot',\n",
    "    'Tomato Early Blight',\n",
    "    'Tomato Healthy',\n",
    "    'Tomato Late Blight',\n",
    "    'Tomato Leaf Mold',\n",
    "    'Tomato Septoria Leaf Spot',\n",
    "    'Tomato Spider Mites',\n",
    "]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bda040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[9.9940312e-01 5.9683027e-04 6.4497718e-10 5.3543253e-10 1.1160387e-14\n",
      " 7.0877753e-16 7.6820848e-11 3.9348008e-10 4.0131235e-23 2.7700147e-14\n",
      " 8.8239543e-28 1.2089531e-18 4.5733163e-23 0.0000000e+00 2.6475101e-22]\n",
      "Prediction: Pepper Bell Bacterial Spot\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "[2.7851493e-04 4.4583013e-16 9.4973463e-01 7.5882529e-03 3.1538099e-15\n",
      " 5.7341404e-10 5.6694695e-03 2.9872486e-02 1.7974696e-08 6.8566832e-03\n",
      " 2.2041774e-14 4.1508645e-12 2.1156896e-14 4.7882338e-20 6.6638628e-09]\n",
      "Prediction: Potato Early Blight\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[4.9699157e-14 4.0359301e-14 1.8305577e-16 7.5516850e-13 2.2512219e-15\n",
      " 1.4591925e-11 2.8298296e-06 7.2362326e-07 3.6750422e-11 5.0048136e-08\n",
      " 1.9972555e-05 9.9997640e-01 2.1149343e-13 6.8599968e-17 9.6379274e-08]\n",
      "Prediction: Tomato Late Blight\n"
     ]
    }
   ],
   "source": [
    "for img_file in predict_img_path.iterdir():\n",
    "    if img_file.suffix.lower() in ['.jpg', '.png']:\n",
    "        # Open image\n",
    "        img = Image.open(img_file)\n",
    "        \n",
    "        # Run through your pipeline (wrap in list or array)\n",
    "        pred = pipeline.predict([img])\n",
    "        print(pred[0])\n",
    "        print(f'Prediction: {predictions[np.argmax(pred)]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
